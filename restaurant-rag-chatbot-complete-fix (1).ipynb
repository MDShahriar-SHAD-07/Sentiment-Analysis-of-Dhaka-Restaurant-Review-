{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Restaurant Intelligence Chatbot - Production System\n",
    "\n",
    "**Enterprise-Grade Conversational AI with RAG**\n",
    "\n",
    "This system integrates:\n",
    "- ‚úÖ Advanced Sentiment Analysis\n",
    "- ‚úÖ Independent Aspect-Based Analysis\n",
    "- ‚úÖ Vector Retrieval (RAG)\n",
    "- ‚úÖ LLM-Driven Recommendations\n",
    "- ‚úÖ Hallucination Prevention\n",
    "- ‚úÖ Production-Grade Error Handling\n",
    "\n",
    "---\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "```\n",
    "User Query ‚Üí Intent Router ‚Üí Vector Retrieval ‚Üí LLM Reasoning ‚Üí Structured Response\n",
    "                ‚Üì                    ‚Üì                ‚Üì\n",
    "         Context Memory      Semantic Search    Grounded Generation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:17:23.827520Z",
     "iopub.status.busy": "2026-02-14T09:17:23.827190Z",
     "iopub.status.idle": "2026-02-14T09:17:42.081404Z",
     "shell.execute_reply": "2026-02-14T09:17:42.080742Z",
     "shell.execute_reply.started": "2026-02-14T09:17:23.827490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "google-adk 1.22.1 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
      "google-adk 1.22.1 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\n",
      "google-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "fastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q \\\n",
    "    chromadb \\\n",
    "    langchain \\\n",
    "    langchain-community \\\n",
    "    sentence-transformers \\\n",
    "    transformers \\\n",
    "    accelerate \\\n",
    "    python-dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:17:58.897661Z",
     "iopub.status.busy": "2026-02-14T09:17:58.897332Z",
     "iopub.status.idle": "2026-02-14T09:18:49.412826Z",
     "shell.execute_reply": "2026-02-14T09:18:49.412079Z",
     "shell.execute_reply.started": "2026-02-14T09:17:58.897629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-14 09:18:17.022034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771060697.380615      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771060697.497390      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1771060698.360497      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771060698.360548      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771060698.360551      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1771060698.360554      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All dependencies loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Core Imports\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ML & NLP\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Vector DB & RAG\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "# Validation\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"‚úÖ All dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:19:11.800535Z",
     "iopub.status.busy": "2026-02-14T09:19:11.800221Z",
     "iopub.status.idle": "2026-02-14T09:19:11.809266Z",
     "shell.execute_reply": "2026-02-14T09:19:11.808551Z",
     "shell.execute_reply.started": "2026-02-14T09:19:11.800511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuration loaded - Device: cuda\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class SystemConfig:\n",
    "    \"\"\"Production-grade configuration with environment variable support\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    data_path: str = \"/kaggle/input/datasets/shahriard07/restaurant-review/dhaka_restaurants.csv\"\n",
    "    vector_db_path: str = \"/kaggle/working/restaurant_vector_db\"\n",
    "    \n",
    "    # Model Configuration\n",
    "    sentiment_model: str = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "    embedding_model: str = \"all-MiniLM-L6-v2\"\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # LLM Configuration\n",
    "    llm_temperature: float = 0.2\n",
    "    max_tokens: int = 512\n",
    "    \n",
    "    # RAG Configuration\n",
    "    retrieval_k: int = 5\n",
    "    similarity_threshold: float = 0.7\n",
    "    \n",
    "    # Aspect Keywords\n",
    "    aspects: Dict[str, List[str]] = field(default_factory=lambda: {\n",
    "        \"food\": [\"food\", \"taste\", \"meal\", \"dish\", \"cuisine\", \"flavor\", \"delicious\", \"‡¶ñ‡¶æ‡¶¨‡¶æ‡¶∞\", \"‡¶∏‡ßç‡¶¨‡¶æ‡¶¶\"],\n",
    "        \"service\": [\"service\", \"staff\", \"waiter\", \"waitress\", \"manager\", \"server\", \"‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶ø‡¶∏\", \"‡¶ï‡¶∞‡ßç‡¶Æ‡ßÄ\"],\n",
    "        \"price\": [\"price\", \"cost\", \"expensive\", \"cheap\", \"value\", \"affordable\", \"‡¶¶‡¶æ‡¶Æ\", \"‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø\"],\n",
    "        \"ambience\": [\"ambience\", \"atmosphere\", \"environment\", \"decor\", \"vibe\", \"‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂\"],\n",
    "        \"cleanliness\": [\"clean\", \"hygiene\", \"sanitary\", \"dirty\", \"‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞\"]\n",
    "    })\n",
    "    \n",
    "    # Negative Triggers\n",
    "    negative_triggers: List[str] = field(default_factory=lambda: [\n",
    "        \"late\", \"slow\", \"rude\", \"bad\", \"cold\", \"delay\", \"terrible\", \"awful\",\n",
    "        \"disappointing\", \"poor\", \"worst\", \"‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™\", \"‡¶¶‡ßá‡¶∞‡¶ø\", \"‡¶†‡¶æ‡¶®‡ßç‡¶°‡¶æ\"\n",
    "    ])\n",
    "    \n",
    "    # Production Settings\n",
    "    batch_size: int = 32\n",
    "    enable_logging: bool = True\n",
    "    fallback_enabled: bool = True\n",
    "\n",
    "# Initialize configuration\n",
    "config = SystemConfig()\n",
    "logger.info(f\"System initialized on device: {config.device}\")\n",
    "print(f\"üîß Configuration loaded - Device: {config.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Data Layer - Schema Validation & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:19:17.658407Z",
     "iopub.status.busy": "2026-02-14T09:19:17.657898Z",
     "iopub.status.idle": "2026-02-14T09:19:17.809052Z",
     "shell.execute_reply": "2026-02-14T09:19:17.808499Z",
     "shell.execute_reply.started": "2026-02-14T09:19:17.658362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Summary:\n",
      "Total Reviews: 977\n",
      "Unique Restaurants: 126\n",
      "Average Review Length: 405 chars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>business_address</th>\n",
       "      <th>business_phone</th>\n",
       "      <th>business_website</th>\n",
       "      <th>business_rating</th>\n",
       "      <th>business_total_reviews</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_additional_info</th>\n",
       "      <th>business_name_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Izumi Japanese Kitchen</td>\n",
       "      <td>House 24 C, Rd 119, Dhaka 1212, Bangladesh</td>\n",
       "      <td>+880 1933-446677</td>\n",
       "      <td>https://m.facebook.com/izumiBD/</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2233</td>\n",
       "      <td>{'name': 'Raunak Maskay', 'thumbnail': 'https:...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>Izumi Japanese Kitchen in Gulshan, Dhaka is on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>izumi japanese kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Izumi Japanese Kitchen</td>\n",
       "      <td>House 24 C, Rd 119, Dhaka 1212, Bangladesh</td>\n",
       "      <td>+880 1933-446677</td>\n",
       "      <td>https://m.facebook.com/izumiBD/</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2233</td>\n",
       "      <td>{'name': 'Dewan Asif', 'thumbnail': 'https://l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>Izumi Japanese Kitchen is a great place for re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>izumi japanese kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Izumi Japanese Kitchen</td>\n",
       "      <td>House 24 C, Rd 119, Dhaka 1212, Bangladesh</td>\n",
       "      <td>+880 1933-446677</td>\n",
       "      <td>https://m.facebook.com/izumiBD/</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2233</td>\n",
       "      <td>{'name': 'Dr. Mehruba Mona', 'thumbnail': 'htt...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Edited 8 months ago</td>\n",
       "      <td>One of the authentic Japanese restaurant in Dh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>izumi japanese kitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            business_name                            business_address  \\\n",
       "0  Izumi Japanese Kitchen  House 24 C, Rd 119, Dhaka 1212, Bangladesh   \n",
       "1  Izumi Japanese Kitchen  House 24 C, Rd 119, Dhaka 1212, Bangladesh   \n",
       "2  Izumi Japanese Kitchen  House 24 C, Rd 119, Dhaka 1212, Bangladesh   \n",
       "\n",
       "     business_phone                 business_website  business_rating  \\\n",
       "0  +880 1933-446677  https://m.facebook.com/izumiBD/              4.5   \n",
       "1  +880 1933-446677  https://m.facebook.com/izumiBD/              4.5   \n",
       "2  +880 1933-446677  https://m.facebook.com/izumiBD/              4.5   \n",
       "\n",
       "   business_total_reviews                                      reviewer_name  \\\n",
       "0                    2233  {'name': 'Raunak Maskay', 'thumbnail': 'https:...   \n",
       "1                    2233  {'name': 'Dewan Asif', 'thumbnail': 'https://l...   \n",
       "2                    2233  {'name': 'Dr. Mehruba Mona', 'thumbnail': 'htt...   \n",
       "\n",
       "   review_rating          review_date  \\\n",
       "0            5.0          a month ago   \n",
       "1            5.0         4 months ago   \n",
       "2            5.0  Edited 8 months ago   \n",
       "\n",
       "                                         review_text  review_additional_info  \\\n",
       "0  Izumi Japanese Kitchen in Gulshan, Dhaka is on...                     NaN   \n",
       "1  Izumi Japanese Kitchen is a great place for re...                     NaN   \n",
       "2  One of the authentic Japanese restaurant in Dh...                     NaN   \n",
       "\n",
       "  business_name_normalized  \n",
       "0   izumi japanese kitchen  \n",
       "1   izumi japanese kitchen  \n",
       "2   izumi japanese kitchen  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ReviewSchema(BaseModel):\n",
    "    \"\"\"Pydantic schema for review validation\"\"\"\n",
    "    business_name: str = Field(..., min_length=1)\n",
    "    review_text: str = Field(..., min_length=10)\n",
    "    review_rating: float = Field(..., ge=1.0, le=5.0)\n",
    "    business_address: Optional[str] = None\n",
    "    \n",
    "    @validator('review_text')\n",
    "    def validate_text(cls, v):\n",
    "        if not isinstance(v, str) or len(v.strip()) < 10:\n",
    "            raise ValueError('Review text must be at least 10 characters')\n",
    "        return v.strip()\n",
    "\n",
    "class DataPipeline:\n",
    "    \"\"\"Production-grade data processing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, config: SystemConfig):\n",
    "        self.config = config\n",
    "        self.df_raw = None\n",
    "        self.df_cleaned = None\n",
    "        \n",
    "    def load_and_validate(self, path: str) -> pd.DataFrame:\n",
    "        \"\"\"Load data with schema validation\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading data from {path}\")\n",
    "            df = pd.read_csv(path)\n",
    "            self.df_raw = df.copy()\n",
    "            \n",
    "            # Validate required columns\n",
    "            required_cols = ['business_name', 'review_text', 'review_rating']\n",
    "            missing = set(required_cols) - set(df.columns)\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing required columns: {missing}\")\n",
    "            \n",
    "            logger.info(f\"‚úÖ Loaded {len(df)} rows\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data loading failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Clean and normalize data\"\"\"\n",
    "        logger.info(\"Starting data cleaning pipeline\")\n",
    "        \n",
    "        # Drop nulls\n",
    "        df_clean = df.dropna(subset=['review_text', 'business_name']).copy()\n",
    "        logger.info(f\"Removed {len(df) - len(df_clean)} null rows\")\n",
    "        \n",
    "        # Ensure text is string\n",
    "        df_clean = df_clean[df_clean['review_text'].apply(lambda x: isinstance(x, str))]\n",
    "        \n",
    "        # Text normalization\n",
    "        df_clean['review_text'] = (\n",
    "            df_clean['review_text']\n",
    "            .str.strip()\n",
    "            .str.replace(r'\\s+', ' ', regex=True)\n",
    "        )\n",
    "        \n",
    "        # Filter short reviews\n",
    "        df_clean = df_clean[df_clean['review_text'].str.len() >= 10]\n",
    "        \n",
    "        # Normalize restaurant names\n",
    "        df_clean['business_name_normalized'] = (\n",
    "            df_clean['business_name']\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "        )\n",
    "        \n",
    "        # Deduplicate\n",
    "        before_dedup = len(df_clean)\n",
    "        df_clean = df_clean.drop_duplicates(subset=['business_name', 'review_text'])\n",
    "        logger.info(f\"Removed {before_dedup - len(df_clean)} duplicate reviews\")\n",
    "        \n",
    "        self.df_cleaned = df_clean.reset_index(drop=True)\n",
    "        logger.info(f\"‚úÖ Cleaning complete - {len(self.df_cleaned)} clean rows\")\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def get_restaurant_index(self) -> Dict[str, int]:\n",
    "        \"\"\"Create restaurant name index for fast lookup\"\"\"\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Data not cleaned yet\")\n",
    "        \n",
    "        return (\n",
    "            self.df_cleaned\n",
    "            .groupby('business_name_normalized')\n",
    "            .size()\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "# Initialize and run data pipeline\n",
    "data_pipeline = DataPipeline(config)\n",
    "df = data_pipeline.load_and_validate(config.data_path)\n",
    "df_cleaned = data_pipeline.clean_data(df)\n",
    "\n",
    "print(f\"\\nüìä Data Summary:\")\n",
    "print(f\"Total Reviews: {len(df_cleaned):,}\")\n",
    "print(f\"Unique Restaurants: {df_cleaned['business_name'].nunique():,}\")\n",
    "print(f\"Average Review Length: {df_cleaned['review_text'].str.len().mean():.0f} chars\")\n",
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ Sentiment Engine - Advanced Analysis with Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:19:23.723068Z",
     "iopub.status.busy": "2026-02-14T09:19:23.722787Z",
     "iopub.status.idle": "2026-02-14T09:19:45.520254Z",
     "shell.execute_reply": "2026-02-14T09:19:45.519439Z",
     "shell.execute_reply.started": "2026-02-14T09:19:23.723043Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1819a624447747c5825750884564e2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff953ac78314d12be78ea03754e4027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7635de4a19d4a54a70c4fe5b29aa9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2997fa9666374a9aba3be94c6827cdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da116641e03421a8069a63f4b4f17f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Sentiment Analysis:   1%|          | 5/977 [00:00<01:47,  9.04it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Sentiment Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 977/977 [00:10<00:00, 96.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≠ Sentiment Distribution:\n",
      "overall_sentiment\n",
      "positive    726\n",
      "negative    213\n",
      "neutral      38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average Confidence: 72.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class SentimentEngine:\n",
    "    \"\"\"Production sentiment analyzer with fallback mechanisms\"\"\"\n",
    "    \n",
    "    def __init__(self, config: SystemConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.fallback_mode = False\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load sentiment model with retry logic\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading sentiment model: {self.config.sentiment_model}\")\n",
    "            self.model = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=self.config.sentiment_model,\n",
    "                device=0 if self.config.device == \"cuda\" else -1\n",
    "            )\n",
    "            logger.info(\"‚úÖ Sentiment model loaded\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Model loading failed: {e}. Enabling fallback mode.\")\n",
    "            self.fallback_mode = True\n",
    "    \n",
    "    def _normalize_label(self, label: str) -> str:\n",
    "        \"\"\"Normalize sentiment labels to standard format\"\"\"\n",
    "        label_lower = label.lower()\n",
    "        if 'pos' in label_lower:\n",
    "            return 'positive'\n",
    "        elif 'neg' in label_lower:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "    \n",
    "    def _fallback_sentiment(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"Rule-based fallback sentiment analysis\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        positive_words = ['good', 'great', 'excellent', 'amazing', 'love', 'best', 'wonderful']\n",
    "        negative_words = ['bad', 'terrible', 'awful', 'worst', 'hate', 'poor', 'disappointing']\n",
    "        \n",
    "        pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "        neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "        \n",
    "        if pos_count > neg_count:\n",
    "            return 'positive', 0.6\n",
    "        elif neg_count > pos_count:\n",
    "            return 'negative', 0.6\n",
    "        else:\n",
    "            return 'neutral', 0.5\n",
    "    \n",
    "    def analyze(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"Analyze sentiment with error handling\"\"\"\n",
    "        try:\n",
    "            if self.fallback_mode or self.model is None:\n",
    "                return self._fallback_sentiment(text)\n",
    "            \n",
    "            # Truncate to model limit\n",
    "            result = self.model(text[:512])[0]\n",
    "            label = self._normalize_label(result['label'])\n",
    "            confidence = result['score']\n",
    "            \n",
    "            return label, confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Sentiment analysis failed for text, using fallback: {e}\")\n",
    "            return self._fallback_sentiment(text)\n",
    "    \n",
    "    def batch_analyze(self, texts: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Batch process with progress tracking\"\"\"\n",
    "        logger.info(f\"Analyzing {len(texts)} reviews\")\n",
    "        \n",
    "        results = []\n",
    "        for text in tqdm(texts, desc=\"Sentiment Analysis\"):\n",
    "            label, confidence = self.analyze(text)\n",
    "            results.append({'sentiment': label, 'confidence': confidence})\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "# Run sentiment analysis\n",
    "sentiment_engine = SentimentEngine(config)\n",
    "sentiment_results = sentiment_engine.batch_analyze(df_cleaned['review_text'].tolist())\n",
    "\n",
    "df_cleaned['overall_sentiment'] = sentiment_results['sentiment']\n",
    "df_cleaned['sentiment_confidence'] = sentiment_results['confidence']\n",
    "\n",
    "print(\"\\nüé≠ Sentiment Distribution:\")\n",
    "print(df_cleaned['overall_sentiment'].value_counts())\n",
    "print(f\"\\nAverage Confidence: {df_cleaned['sentiment_confidence'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Aspect Extraction - Independent Analysis (NOT Copied from Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:19:57.846032Z",
     "iopub.status.busy": "2026-02-14T09:19:57.845763Z",
     "iopub.status.idle": "2026-02-14T09:20:15.736157Z",
     "shell.execute_reply": "2026-02-14T09:20:15.735549Z",
     "shell.execute_reply.started": "2026-02-14T09:19:57.846013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aspect Analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 977/977 [00:17<00:00, 54.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Aspect Analysis Summary:\n",
      "\n",
      "FOOD ‚Üí 837 mentions\n",
      "food_sentiment\n",
      "positive    595\n",
      "negative    177\n",
      "neutral      65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SERVICE ‚Üí 508 mentions\n",
      "service_sentiment\n",
      "positive    400\n",
      "negative     88\n",
      "neutral      20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "PRICE ‚Üí 306 mentions\n",
      "price_sentiment\n",
      "positive    130\n",
      "negative    113\n",
      "neutral      63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMBIENCE ‚Üí 388 mentions\n",
      "ambience_sentiment\n",
      "positive    328\n",
      "negative     41\n",
      "neutral      19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CLEANLINESS ‚Üí 74 mentions\n",
      "cleanliness_sentiment\n",
      "positive    55\n",
      "negative    13\n",
      "neutral      6\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Aspect Extraction Module\n",
    "# ==============================\n",
    "\n",
    "class AspectAnalyzer:\n",
    "    \"\"\"Advanced aspect-based sentiment analyzer (Production Safe)\"\"\"\n",
    "\n",
    "    def __init__(self, config: SystemConfig, sentiment_engine: SentimentEngine):\n",
    "        self.config = config\n",
    "        self.sentiment_engine = sentiment_engine\n",
    "        self.aspects = config.aspects\n",
    "\n",
    "    def extract_aspect_text(self, text: str, aspect: str) -> Optional[str]:\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return None\n",
    "\n",
    "        text_lower = text.lower()\n",
    "        keywords = self.aspects.get(aspect, [])\n",
    "\n",
    "        # Aspect not mentioned at all\n",
    "        if not any(keyword in text_lower for keyword in keywords):\n",
    "            return None\n",
    "\n",
    "        # Extract relevant sentences\n",
    "        sentences = text.split(\".\")\n",
    "        relevant = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if any(keyword in sentence.lower() for keyword in keywords):\n",
    "                relevant.append(sentence.strip())\n",
    "\n",
    "        return \" \".join(relevant) if relevant else text[:200]\n",
    "\n",
    "    def analyze_aspect(self, text: str, aspect: str) -> Dict[str, Any]:\n",
    "        aspect_text = self.extract_aspect_text(text, aspect)\n",
    "\n",
    "        if aspect_text is None:\n",
    "            return {\n",
    "                \"mentioned\": False,\n",
    "                \"sentiment\": None,\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "\n",
    "        sentiment, confidence = self.sentiment_engine.analyze(aspect_text)\n",
    "\n",
    "        return {\n",
    "            \"mentioned\": True,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "\n",
    "    def batch_analyze(self, texts: List[str]) -> pd.DataFrame:\n",
    "        results = []\n",
    "\n",
    "        for text in tqdm(texts, desc=\"Aspect Analysis\"):\n",
    "            row = {}\n",
    "\n",
    "            for aspect in self.aspects.keys():\n",
    "                data = self.analyze_aspect(text, aspect)\n",
    "\n",
    "                row[f\"{aspect}_mentioned\"] = bool(data[\"mentioned\"])\n",
    "                row[f\"{aspect}_sentiment\"] = data[\"sentiment\"]\n",
    "                row[f\"{aspect}_confidence\"] = float(data[\"confidence\"])\n",
    "\n",
    "            results.append(row)\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Run Aspect Analysis\n",
    "# ==============================\n",
    "\n",
    "aspect_analyzer = AspectAnalyzer(config, sentiment_engine)\n",
    "\n",
    "aspect_results = aspect_analyzer.batch_analyze(\n",
    "    df_cleaned[\"review_text\"].fillna(\"\").tolist()\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Remove previous aspect columns (if re-run)\n",
    "# ------------------------------\n",
    "\n",
    "aspect_prefixes = list(config.aspects.keys())\n",
    "\n",
    "cols_to_drop = [\n",
    "    col for col in df_cleaned.columns\n",
    "    if any(col.startswith(prefix) for prefix in aspect_prefixes)\n",
    "]\n",
    "\n",
    "df_cleaned = df_cleaned.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# ------------------------------\n",
    "# Safe Merge\n",
    "# ------------------------------\n",
    "\n",
    "df_cleaned = pd.concat(\n",
    "    [\n",
    "        df_cleaned.reset_index(drop=True),\n",
    "        aspect_results.reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Safe Aspect Summary\n",
    "# ==============================\n",
    "\n",
    "print(\"\\nüîç Aspect Analysis Summary:\")\n",
    "\n",
    "for aspect in config.aspects.keys():\n",
    "\n",
    "    col_mentioned = f\"{aspect}_mentioned\"\n",
    "    col_sentiment = f\"{aspect}_sentiment\"\n",
    "\n",
    "    if col_mentioned not in df_cleaned.columns:\n",
    "        continue\n",
    "\n",
    "    mask = df_cleaned[col_mentioned] == True\n",
    "    mentioned_count = int(mask.sum())\n",
    "\n",
    "    if mentioned_count > 0:\n",
    "\n",
    "        sentiment_dist = (\n",
    "            df_cleaned.loc[mask, col_sentiment]\n",
    "            .dropna()\n",
    "            .value_counts()\n",
    "        )\n",
    "\n",
    "        print(f\"\\n{aspect.upper()} ‚Üí {mentioned_count} mentions\")\n",
    "        print(sentiment_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Conflict Detection - Multi-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:20:24.359658Z",
     "iopub.status.busy": "2026-02-14T09:20:24.358992Z",
     "iopub.status.idle": "2026-02-14T09:20:24.399028Z",
     "shell.execute_reply": "2026-02-14T09:20:24.398300Z",
     "shell.execute_reply.started": "2026-02-14T09:20:24.359631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Conflict Analysis:\n",
      "rating_sentiment_conflict\n",
      "No Conflict               799\n",
      "Ambiguous Experience       87\n",
      "Hidden Dissatisfaction     82\n",
      "Politeness Bias             9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total Conflicts: 364 (37.3%)\n"
     ]
    }
   ],
   "source": [
    "class ConflictDetector:\n",
    "    \"\"\"Advanced conflict detection system\"\"\"\n",
    "    \n",
    "    def detect_rating_sentiment_conflict(self, row: pd.Series) -> str:\n",
    "        rating = row.get('review_rating', 0)\n",
    "        sentiment = row.get('overall_sentiment')\n",
    "        \n",
    "        if rating >= 4 and sentiment == 'negative':\n",
    "            return 'Hidden Dissatisfaction'\n",
    "        elif rating <= 2 and sentiment == 'positive':\n",
    "            return 'Politeness Bias'\n",
    "        elif rating == 3 and sentiment in ['positive', 'negative']:\n",
    "            return 'Ambiguous Experience'\n",
    "        else:\n",
    "            return 'No Conflict'\n",
    "    \n",
    "    def detect_aspect_conflicts(self, row: pd.Series, aspects: List[str]) -> int:\n",
    "        overall = row.get('overall_sentiment')\n",
    "        conflicts = 0\n",
    "        \n",
    "        for aspect in aspects:\n",
    "            if row.get(f'{aspect}_mentioned', False):\n",
    "                aspect_sent = row.get(f'{aspect}_sentiment')\n",
    "                if aspect_sent and aspect_sent != overall:\n",
    "                    conflicts += 1\n",
    "        \n",
    "        return conflicts\n",
    "    \n",
    "    def analyze(self, df: pd.DataFrame, aspects: List[str]) -> pd.DataFrame:\n",
    "        logger.info(\"Running conflict detection\")\n",
    "        \n",
    "        df['rating_sentiment_conflict'] = df.apply(\n",
    "            self.detect_rating_sentiment_conflict, axis=1\n",
    "        )\n",
    "        \n",
    "        df['aspect_conflict_count'] = df.apply(\n",
    "            lambda row: self.detect_aspect_conflicts(row, aspects), axis=1\n",
    "        )\n",
    "        \n",
    "        df['has_conflict'] = (\n",
    "            (df['rating_sentiment_conflict'] != 'No Conflict') |\n",
    "            (df['aspect_conflict_count'] > 0)\n",
    "        )\n",
    "        \n",
    "        logger.info(\"‚úÖ Conflict detection complete\")\n",
    "        return df\n",
    "\n",
    "conflict_detector = ConflictDetector()\n",
    "df_cleaned = conflict_detector.analyze(df_cleaned, list(config.aspects.keys()))\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Conflict Analysis:\")\n",
    "print(df_cleaned['rating_sentiment_conflict'].value_counts())\n",
    "print(f\"\\nTotal Conflicts: {df_cleaned['has_conflict'].sum():,} ({df_cleaned['has_conflict'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Vector Database - RAG Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:20:42.367019Z",
     "iopub.status.busy": "2026-02-14T09:20:42.366731Z",
     "iopub.status.idle": "2026-02-14T09:20:47.184131Z",
     "shell.execute_reply": "2026-02-14T09:20:47.183510Z",
     "shell.execute_reply.started": "2026-02-14T09:20:42.366996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854a301b0f50468c8d7ee7c06af9fdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035377e4a3394b569c6d94279e2066fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee53e31f2f446f2b08707bc6a95bfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef16d866e014c2a8829320a7fc61bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd4f40385d94cfbaa5733f4765be4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12de779f64a248d4886d7882f1af382b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2c33968f574d1a9f46261467423334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a103f0d0dd314caea3a9685db405876e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659eec5424474c77bbe1656455460eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885ca0d57ae24492b13d63a927dce197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349fd479d0a8466a942ec1c97e0a65cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóÑÔ∏è Vector Store Ready - 977 documents\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "class VectorStoreManager:\n",
    "    \"\"\"Production vector database manager\"\"\"\n",
    "    \n",
    "    def __init__(self, config: SystemConfig):\n",
    "        self.config = config\n",
    "        self.embeddings = None\n",
    "        self.vector_store = None\n",
    "        self._initialize_embeddings()\n",
    "    \n",
    "    def _initialize_embeddings(self):\n",
    "        try:\n",
    "            logger.info(f\"Loading embedding model: {self.config.embedding_model}\")\n",
    "            self.embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=self.config.embedding_model\n",
    "            )\n",
    "            logger.info(\"‚úÖ Embedding model loaded\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Embedding model loading failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def create_documents(self, df: pd.DataFrame) -> List[Document]:\n",
    "        logger.info(f\"Creating {len(df)} documents\")\n",
    "        documents = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            aspect_summary = {}\n",
    "            for aspect in self.config.aspects.keys():\n",
    "                if row.get(f'{aspect}_mentioned', False):\n",
    "                    aspect_summary[aspect] = row.get(f'{aspect}_sentiment')\n",
    "            \n",
    "            doc = Document(\n",
    "                page_content=row['review_text'],\n",
    "                metadata={\n",
    "                    'restaurant': row['business_name'],\n",
    "                    'restaurant_normalized': row['business_name_normalized'],\n",
    "                    'rating': float(row['review_rating']),\n",
    "                    'sentiment': row['overall_sentiment'],\n",
    "                    'confidence': float(row['sentiment_confidence']),\n",
    "                    'aspects': json.dumps(aspect_summary),\n",
    "                    'conflict': row['rating_sentiment_conflict'],\n",
    "                    'has_conflict': bool(row['has_conflict'])\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def build_vector_store(self, documents: List[Document]) -> Chroma:\n",
    "        try:\n",
    "            if os.path.exists(self.config.vector_db_path):\n",
    "                shutil.rmtree(self.config.vector_db_path)\n",
    "            \n",
    "            logger.info(\"Building vector store...\")\n",
    "            self.vector_store = Chroma.from_documents(\n",
    "                documents=documents,\n",
    "                embedding=self.embeddings,\n",
    "                persist_directory=self.config.vector_db_path,\n",
    "                client_settings=Settings(anonymized_telemetry=False)\n",
    "            )\n",
    "            \n",
    "            logger.info(\"‚úÖ Vector store built\")\n",
    "            return self.vector_store\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Vector store creation failed: {e}\")\n",
    "            raise\n",
    "\n",
    "vector_manager = VectorStoreManager(config)\n",
    "documents = vector_manager.create_documents(df_cleaned)\n",
    "vector_store = vector_manager.build_vector_store(documents)\n",
    "\n",
    "print(f\"\\nüóÑÔ∏è Vector Store Ready - {len(documents):,} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 9: Mock LLM ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:20:53.242831Z",
     "iopub.status.busy": "2026-02-14T09:20:53.242086Z",
     "iopub.status.idle": "2026-02-14T09:20:53.254730Z",
     "shell.execute_reply": "2026-02-14T09:20:53.254034Z",
     "shell.execute_reply.started": "2026-02-14T09:20:53.242804Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mock LLM initialized (replace with real LLM for production)\n"
     ]
    }
   ],
   "source": [
    "class MockLLM(LLM):\n",
    "    \"\"\"Mock LLM for demonstration (replace with real LLM in production)\"\"\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"mock\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        # Extract context from prompt\n",
    "        if \"Context:\" in prompt:\n",
    "            context_section = prompt.split(\"Context:\")[1].split(\"Question:\")[0]\n",
    "            reviews = [r.strip() for r in context_section.strip().split(\"\\n\\n\") if r.strip()]\n",
    "\n",
    "            # Simple rule-based response\n",
    "            if len(reviews) > 0:\n",
    "                return f\"Based on {len(reviews)} reviews analyzed, I can provide insights. The reviews show varying experiences across different aspects.\"\n",
    "            else:\n",
    "                return \"Insufficient review evidence to provide a reliable recommendation.\"\n",
    "\n",
    "        return \"I can only answer based on the provided review context.\"\n",
    "\n",
    "llm = MockLLM()\n",
    "print(\"‚úÖ Mock LLM initialized (replace with real LLM for production)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 10: RAG Chatbot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:20:58.570308Z",
     "iopub.status.busy": "2026-02-14T09:20:58.570020Z",
     "iopub.status.idle": "2026-02-14T09:20:58.580771Z",
     "shell.execute_reply": "2026-02-14T09:20:58.580160Z",
     "shell.execute_reply.started": "2026-02-14T09:20:58.570284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG Chatbot initialized\n"
     ]
    }
   ],
   "source": [
    "class RAGChatbot:\n",
    "    \"\"\"Production RAG chatbot with grounding\"\"\"\n",
    "\n",
    "    def __init__(self, vector_store: Chroma, llm: LLM, config: SystemConfig):\n",
    "        self.vector_store = vector_store\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "        self.qa_chain = self._build_chain()\n",
    "\n",
    "    def _build_chain(self):\n",
    "        template = \"\"\"You are a restaurant intelligence advisor. Answer ONLY using the provided reviews below.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- Only use information from the Context section\n",
    "- If insufficient evidence, respond: \"Insufficient review evidence to provide a reliable recommendation.\"\n",
    "- Never make assumptions or use external knowledge\n",
    "- Always cite specific reviews when making claims\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer (grounded in reviews only):\"\"\"\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "        chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vector_store.as_retriever(\n",
    "                search_kwargs={\"k\": self.config.retrieval_k}        \n",
    "            ),\n",
    "            chain_type_kwargs={\"prompt\": prompt},\n",
    "            return_source_documents=True\n",
    "        )\n",
    "\n",
    "        return chain\n",
    "\n",
    "    def query(self, question: str, restaurant_filter: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Query with optional restaurant filtering\"\"\"\n",
    "        try:\n",
    "            if restaurant_filter:\n",
    "                # Filter by restaurant\n",
    "                filter_dict = {\"restaurant_normalized\": restaurant_filter.lower()}\n",
    "                docs = self.vector_store.similarity_search(\n",
    "                    question, k=self.config.retrieval_k, filter=filter_dict\n",
    "                )\n",
    "\n",
    "                if not docs:\n",
    "                    return {\n",
    "                        \"answer\": f\"No reviews found for '{restaurant_filter}'\",\n",
    "                        \"sources\": [],\n",
    "                        \"confidence\": 0.0\n",
    "                    }\n",
    "\n",
    "                # Build context manually\n",
    "                context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "                answer = self.llm(f\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\")\n",
    "\n",
    "                return {\n",
    "                    \"answer\": answer,\n",
    "                    \"sources\": docs,\n",
    "                    \"confidence\": 0.8\n",
    "                }\n",
    "            else:\n",
    "                result = self.qa_chain({\"query\": question})\n",
    "                return {\n",
    "                    \"answer\": result['result'],\n",
    "                    \"sources\": result.get('source_documents', []),  \n",
    "                    \"confidence\": 0.8\n",
    "                }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Query failed: {e}\")\n",
    "            return {\n",
    "                \"answer\": \"An error occurred processing your query.\",\n",
    "                \"sources\": [],\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "\n",
    "chatbot = RAGChatbot(vector_store, llm, config)\n",
    "print(\"‚úÖ RAG Chatbot initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 11: Recommendation Engine ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:21:03.348505Z",
     "iopub.status.busy": "2026-02-14T09:21:03.347761Z",
     "iopub.status.idle": "2026-02-14T09:21:03.358400Z",
     "shell.execute_reply": "2026-02-14T09:21:03.357737Z",
     "shell.execute_reply.started": "2026-02-14T09:21:03.348477Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Recommendation Engine initialized\n"
     ]
    }
   ],
   "source": [
    "class RecommendationEngine:\n",
    "    \"\"\"Advanced recommendation scoring system\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, config: SystemConfig):     \n",
    "        self.df = df\n",
    "        self.config = config\n",
    "\n",
    "    def calculate_score(self, restaurant_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate comprehensive recommendation score\"\"\"\n",
    "        restaurant_df = self.df[\n",
    "            self.df['business_name_normalized'] == restaurant_name.lower()\n",
    "        ]\n",
    "\n",
    "        if len(restaurant_df) == 0:\n",
    "            return {\"error\": \"Restaurant not found\"}\n",
    "\n",
    "        if len(restaurant_df) < 3:\n",
    "            return {\"error\": \"Insufficient reviews (minimum 3 required)\", \"count\": len(restaurant_df)}\n",
    "\n",
    "        # Sentiment Distribution (40%)\n",
    "        sentiment_score = (restaurant_df['overall_sentiment'] == 'positive').mean() * 40\n",
    "\n",
    "        # Aspect Scores (30%)\n",
    "        aspect_scores = {}\n",
    "        aspect_total = 0\n",
    "        for aspect in self.config.aspects.keys():\n",
    "            mentioned = restaurant_df[f'{aspect}_mentioned']        \n",
    "            if mentioned.sum() > 0:\n",
    "                pos_rate = (\n",
    "                    restaurant_df[mentioned][f'{aspect}_sentiment'] == 'positive'\n",
    "                ).mean()\n",
    "                aspect_scores[aspect] = pos_rate\n",
    "                aspect_total += pos_rate\n",
    "\n",
    "        aspect_score = (aspect_total / len(aspect_scores)) * 30 if aspect_scores else 0\n",
    "\n",
    "        # Conflict Penalty (15%)\n",
    "        conflict_rate = restaurant_df['has_conflict'].mean()        \n",
    "        conflict_score = (1 - conflict_rate) * 15\n",
    "\n",
    "        # Volume Bonus (10%)\n",
    "        volume_score = min(len(restaurant_df) / 100, 1.0) * 10      \n",
    "\n",
    "        # Confidence (5%)\n",
    "        confidence_score = restaurant_df['sentiment_confidence'].mean() * 5\n",
    "\n",
    "        total_score = sentiment_score + aspect_score + conflict_score + volume_score + confidence_score\n",
    "\n",
    "        # Extract insights\n",
    "        strengths = []\n",
    "        weaknesses = []\n",
    "\n",
    "        for aspect, score in aspect_scores.items():\n",
    "            if score > 0.7:\n",
    "                strengths.append(f\"Excellent {aspect}\")\n",
    "            elif score < 0.4:\n",
    "                weaknesses.append(f\"Poor {aspect}\")\n",
    "\n",
    "        risk_factors = []\n",
    "        if conflict_rate > 0.15:\n",
    "            risk_factors.append(f\"{conflict_rate:.0%} hidden dissatisfaction\")\n",
    "\n",
    "        return {\n",
    "            \"score\": round(total_score, 1),\n",
    "            \"review_count\": len(restaurant_df),\n",
    "            \"sentiment_distribution\": restaurant_df['overall_sentiment'].value_counts().to_dict(),\n",
    "            \"aspect_scores\": {k: round(v*100, 1) for k, v in aspect_scores.items()},\n",
    "            \"strengths\": strengths,\n",
    "            \"weaknesses\": weaknesses,\n",
    "            \"risk_factors\": risk_factors,\n",
    "            \"conflict_rate\": round(conflict_rate * 100, 1)\n",
    "        }\n",
    "\n",
    "rec_engine = RecommendationEngine(df_cleaned, config)\n",
    "print(\"‚úÖ Recommendation Engine initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 12: Interactive Chat Interface ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:21:10.732357Z",
     "iopub.status.busy": "2026-02-14T09:21:10.731567Z",
     "iopub.status.idle": "2026-02-14T09:21:10.758415Z",
     "shell.execute_reply": "2026-02-14T09:21:10.757506Z",
     "shell.execute_reply.started": "2026-02-14T09:21:10.732328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ü§ñ INTERACTIVE RESTAURANT CHATBOT\n",
      "================================================================================\n",
      "\n",
      "Ask questions about restaurants or get recommendations!\n",
      "\n",
      "Example questions:\n",
      "  - Which restaurant has the best food?\n",
      "  - Tell me about the service quality\n",
      "  - Is Izumi Japanese Kitchen good for couples?\n",
      "  - What do people say about prices?\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7854e0fc0fb34138b3c2bf362a0b73fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üçΩÔ∏è Restaurant Intelligence Chatbot</h3>'), Text(value='', description='Question‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Chat history\n",
    "chat_history = []\n",
    "\n",
    "# Create UI components\n",
    "output_area = widgets.Output()\n",
    "question_input = widgets.Text(\n",
    "    placeholder='Ask about restaurants (e.g., \"Best food quality?\")',\n",
    "    description='Question:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "restaurant_input = widgets.Text(\n",
    "    placeholder='Optional: Filter by restaurant name',\n",
    "    description='Restaurant:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "send_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    icon='paper-plane'\n",
    ")\n",
    "clear_button = widgets.Button(\n",
    "    description='Clear Chat',\n",
    "    button_style='warning',\n",
    "    icon='trash'\n",
    ")\n",
    "\n",
    "def format_chat_message(role, message, sources=None):\n",
    "    \"\"\"Format chat message with styling\"\"\"\n",
    "    if role == \"user\":\n",
    "        return f'''\n",
    "        <div style=\"background: #e3f2fd; padding: 10px; margin: 5px 0; border-radius: 10px; border-left: 4px solid #2196F3;\">\n",
    "            <strong>üßë You:</strong> {message}\n",
    "        </div>\n",
    "        '''\n",
    "    else:\n",
    "        sources_html = \"\"\n",
    "        if sources and len(sources) > 0:\n",
    "            sources_html = f\"<br><small>üìö Based on {len(sources)} reviews</small>\"\n",
    "        return f'''\n",
    "        <div style=\"background: #f1f8e9; padding: 10px; margin: 5px 0; border-radius: 10px; border-left: 4px solid #8BC34A;\">\n",
    "            <strong>ü§ñ Assistant:</strong> {message}{sources_html}  \n",
    "        </div>\n",
    "        '''\n",
    "\n",
    "def send_message(b):\n",
    "    \"\"\"Handle send button click\"\"\"\n",
    "    question = question_input.value.strip()\n",
    "    restaurant = restaurant_input.value.strip() if restaurant_input.value.strip() else None\n",
    "\n",
    "    if not question:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            for msg in chat_history:\n",
    "                display(HTML(msg))\n",
    "            display(HTML('<p style=\"color: red;\">‚ö†Ô∏è Please enter a qquestion</p>'))\n",
    "        return\n",
    "\n",
    "    # Add user message to history\n",
    "    user_msg = format_chat_message(\"user\", question + (f\" (Restaurant: {restaurant})\" if restaurant else \"\"))\n",
    "    chat_history.append(user_msg)\n",
    "\n",
    "    # Get response\n",
    "    result = chatbot.query(question, restaurant_filter=restaurant)  \n",
    "\n",
    "    # Add bot response to history\n",
    "    bot_msg = format_chat_message(\"assistant\", result['answer'], result.get('sources'))\n",
    "    chat_history.append(bot_msg)\n",
    "\n",
    "    # Update display\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        for msg in chat_history:\n",
    "            display(HTML(msg))\n",
    "\n",
    "    # Clear inputs\n",
    "    question_input.value = \"\"\n",
    "    restaurant_input.value = \"\"\n",
    "\n",
    "def clear_chat(b):\n",
    "    \"\"\"Clear chat history\"\"\"\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        display(HTML('<p style=\"color: #666;\">Chat cleared. Start a new conversation!</p>'))\n",
    "\n",
    "# Attach event handlers\n",
    "send_button.on_click(send_message)\n",
    "clear_button.on_click(clear_chat)\n",
    "question_input.on_submit(lambda x: send_message(None))\n",
    "\n",
    "# Display UI\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ü§ñ INTERACTIVE RESTAURANT CHATBOT\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAsk questions about restaurants or get recommendations!\")  \n",
    "print(\"\\nExample questions:\")\n",
    "print(\"  - Which restaurant has the best food?\")\n",
    "print(\"  - Tell me about the service quality\")\n",
    "print(\"  - Is Izumi Japanese Kitchen good for couples?\")\n",
    "print(\"  - What do people say about prices?\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üçΩÔ∏è Restaurant Intelligence Chatbot</h3>\"),    \n",
    "    question_input,\n",
    "    restaurant_input,\n",
    "    widgets.HBox([send_button, clear_button]),\n",
    "    output_area\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì§ Data Export for FastAPI\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create data directory\n",
    "data_dir = \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Export processed DataFrame to CSV\n",
    "output_path = os.path.join(data_dir, \"processed_reviews.csv\")\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Exported {len(df_cleaned)} reviews to {output_path}\")\n",
    "\n",
    "# Export as pickle (faster loading)\n",
    "pickle_path = os.path.join(data_dir, \"processed_reviews.pkl\")\n",
    "df_cleaned.to_pickle(pickle_path)\n",
    "print(f\"‚úÖ Exported pickle to {pickle_path}\")\n",
    "\n",
    "# Copy vector database\n",
    "source_vector_db = \"/kaggle/working/restaurant_vector_db\"\n",
    "target_vector_db = \"restaurant_vector_db\"\n",
    "\n",
    "if os.path.exists(source_vector_db):\n",
    "    if os.path.exists(target_vector_db):\n",
    "        shutil.rmtree(target_vector_db)\n",
    "    shutil.copytree(source_vector_db, target_vector_db)\n",
    "    print(f\"‚úÖ Copied vector database to {target_vector_db}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Vector database not found\")\n",
    "\n",
    "print(\"\\nüéâ Data export complete!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - data/processed_reviews.csv\")\n",
    "print(\"  - data/processed_reviews.pkl\")\n",
    "print(\"  - restaurant_vector_db/ (folder)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9461926,
     "sourceId": 14798432,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9484740,
     "sourceId": 14830169,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
